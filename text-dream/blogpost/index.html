<!--
@license
Copyright 2019 Google Inc.
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at
    http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->
<html>
<head>
<link rel="icon"
      type="image/png"
      href="./icon.png"/>
<link rel="stylesheet" href="style.css">

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Language, trees, and geometry in neural networks">
<!-- <meta property="og:description" content="Language, trees, and geometry in neural networks"> -->
<!-- <meta property="og:url" content=""> -->
<meta property="og:image" content="header.png">
<meta name="twitter:card" content="summary_large_image">


<title>Deep Dreaming with BERT</title>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>
<script type="text/javascript"
  src="../third_party/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

</head>

<!-- <img src="header.png" style="width:1051px;height:280px"> -->


<body>
<div id='header'></div>
<div >
  <h1 style="margin-top:20px; margin-bottom:20px">What does BERT dream of, and how can we interpret
    it?</h1>
</div>





<span style="color:#999;font-style:italic">
A visual investigation of nightmares in sesame street, by Alex BÃ¤uerle, James Wexler,
and Martin Wattenberg.
</span>
<p>


<a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">DeepDream</a>, which has been intensively studied for neural networks for image data, aims at providing explanations for what individual neurons react to.
It changes the input to the network through gradient decent, with the goal of maximizing the activation value of neurons in these networks.
This can be thought of as similar to the initial training process, where through many iterations, we try to optimize a mathematical equation.
But instead of updating network parameters, DeepDream updates the input sample.
What this leads to is somewhat psychedelic but very interesting images, that can reveal to what kind of input these neurons react.

<p>
We wanted to know how <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT</a> reacts to different inputs.
BERT is a model for natural language understanding.
It can be used for tasks such as sentiment analysis or next sentence prediction.
In another blogpost, (link emilys work) investigated this using corpus search.
They searched for sentences that highly activate certain neurons of the network.
As this provided some promising results, we wanted to see if we can get even better with dreaming.

<p>
When dreaming for images, the input to the model is gradually changed.
Looking at a single pixel in the input image, this could be a slow change from green to red.
The green value would gradually go down, while the red value would increase.
Language, however, is made of discrete structures.
Thus, there is no such gradual change to be made.
We can, for examlple, not slowly go from the word "green" to the word "red", as everything in between does not make sense.
We therefore have to use a little trick.
The trick that worked best for us (later you will see that best does not necessarily mean perfect in the realm of deep learning), is called the softmax-trick, and has already been used in a <a href="https://www.aclweb.org/anthology/W18-5437">paper from 2018 by Poerner et. al.</a>.
This trick allows us to soften the requirement of dicrete tokens, and instead input a linear combination of tokens into the model.
To assure that we do not end up with something crazy, it uses two mechanisms.
First, it constrains this linear combination to in its sum only consist of one token.
This is done by taking the softmax function over this smooth input distribution, i.e. $softmax(soft_token_distribution)$.
This, however, still leaves the problem that we can end up with any linear combination of tokens that sums to one, including such ones that are in between real tokens.
Therefore, we also make use of a temperature parameter.
Before applying the softmax function, we divide our token distribution vector by this temperature.
Dividing by large temperature values means that the softmax result will be even more smooth, whereas  dividing by very low temperature values results in a more spiky softmax function.
We want the model to be able to first explore different linear combinations of tokens, before having to decide on one token.
This can be done by slowly decreasing the temperature alongside the dreaming process.


<h2>What are BERTs dreams like?</h2>

Now that we know how DeepDream can be used in combination with text models, how do those results look like?
Well, very unpredictable.
Fore some neurons, it is possible to produce sentences that highly activate them (baseline always being the the results from corpus search).
However, other neurons to not give us these results at all.
There are different options of which words to be changed by the model.
We always keep the CLS and SEP tokens static.
CLS is a spectial classification token used by BERT for some downstream tasks, while SEP marks the end of a sentence.
When we allow the model to change these tokens as well, it seems to be confused and the approach is likely to fail.
In between those, one can change anything from one word to the whole sentence.
When changing single words, the model often finds one that leads to a high activation, but not always.
For whole sentences, the sucess rate is slightly reduced to something around 50% in our experience.

<p>
In the first place, this was surprising to us.
This method uses gradient decent and seemed to work for other models (<a href="https://www.aclweb.org/anthology/W18-5437">see Poerner et. al. 2018</a>).
However, BERT is a complex model, arguably much more complex than the models that have been previously investigated with this method.
Nonetheless, we wanted to sanity-check our approach, but more on that later.

<p>
So, why is BERT such a bad dreamer?
This is a question we try to answer <a href="https://ai.google/research/teams/brain/pair">PAIR</a>-style, by providing explainability tools to visually inspect those dreaming results.
We built visualization tools that allow users of Deep Draeming with text to investigate their dreaming processes.
We use them to reason about our approaches with BERT, but if you run into similar problems, feel free to use them with any model.
All these tools are publicly available on <a href="https://github.com/PAIR-code/interpretability/text-dream">GitHub</a>.

<h3>Visualizing the dreaming process</h3>

The first question we wanted to answer for these dreaming processes is how the input representation evolves over said process.
Here, it is interesting to look at when and how the model replaces certain words in the input.
At the same time, we want to see how the activation value of the neuron we are trying to maximize is evolving alongside the change of temperature which we use to force the model to pick real tokens.
Additionally, we compare the evolvement of this activation value to the activation we would get if we were to ignore the linear combination of tokens that we obtain using the softmax-trick, and insted snap our input to the top ranked tokens of the softmax function.

<h2>Conclusion</h2>

We do not know exactly why things play out the way they do when we try to let BERT dream.
But thanks to these interesting visualization approaches, we have some ideas for those questions.
Additionally, the dreaming process provided us with interesting insights of how BERT sees some inputs, for exapmple what the model puts its focus on for different layers.
This is in line with findings from other approaches, such as (ians work) and (bert explain paper).

<p>
  <span style="color:#999;font-style:italic">
    Many thanks to (think about whom to thank) Nina Poerner, and Ian Tenney for helpful feedback and discussions about this research.</i>
</span>

</body>

<script src="https://d3js.org/d3.v4.min.js"></script>
<script>var d3interval = d3.interval</script>
<script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script>
<script src='https://unpkg.com/d3-jetpack@2.0.20/build/d3-jetpack.js'></script>

<script src='script.js'></script>

</html>
